# Copyright (C) 2021 Nicolas Lamirault <nicolas.lamirault@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: grafana-agent-mixin-alerts
  labels:
    app: prometheus
spec:
  groups:
  - name: grafana-agent-tracing
    rules:
    - alert: AgentTracingReceiverErrors
      annotations:
        message: |
          Receiver {{ $labels.receiver }} is experiencing {{ printf "%.2f" $value }}% errors.
      expr: |
        100 * sum(rate(traces_receiver_refused_spans{receiver!="otlp/lb"}[1m])) by (cluster, namespace, receiver)
          /
        (sum(rate(traces_receiver_refused_spans{receiver!="otlp/lb"}[1m])) by (cluster, namespace, receiver) + sum(rate(traces_receiver_accepted_spans{receiver!="otlp/lb"}[1m])) by (cluster, namespace, receiver))
          > 10
      for: 15m
      labels:
        severity: warning
    - alert: AgentTracingExporterErrors
      annotations:
        message: |
          Exporter {{ $labels.exporter }} is experiencing {{ printf "%.2f" $value }}% errors.
      expr: |
        100 * sum(rate(traces_exporter_send_failed_spans{exporter!="otlp"}[1m])) by (cluster, namespace, exporter)
          /
        (sum(rate(traces_exporter_send_failed_spans{exporter!="otlp"}[1m])) by (cluster, namespace, exporter) + sum(rate(traces_exporter_sent_spans{exporter!="otlp"}[1m])) by (cluster, namespace, exporter))
          > 10
      for: 15m
      labels:
        severity: warning
    - alert: AgentTracingLoadBalancingErrors
      annotations:
        message: |
          Load balacing is experiencing {{ printf "%.2f" $value }}% errors.
      expr: |
        100 * sum(rate(traces_loadbalancer_backend_outcome{success="false"}[1m])) by (cluster, namespace)
          /
        sum(rate(traces_loadbalancer_backend_outcome{success="true"}[1m])) by (cluster, namespace)
          > 10
      for: 15m
      labels:
        severity: warning
  - name: GrafanaAgentSmokeChecks
    rules:
    - alert: GrafanaAgentDown
      annotations:
        summary: '{{ $labels.job }} is down'
      expr: |
        up{
          namespace="agent-smoke-test",
          pod=~"grafana-agent-smoke-test-(0|cluster-0|cluster-1|cluster-2)",
        } == 0
      for: 5m
    - alert: GrafanaAgentFlapping
      annotations:
        summary: '{{ $labels.job }} is flapping'
      expr: |
        avg_over_time(up{
          namespace="agent-smoke-test",
          pod=~"grafana-agent-smoke-test-(0|cluster-0|cluster-1|cluster-2)",
        }[5m]) < 1
      for: 15m
    - alert: GrafanaAgentCPUHigh
      annotations:
        summary: '{{ $labels.pod }} is using more than 0.0013441 CPU per 1000 series
          over the last 5 minutes'
      expr: |
        (sum by (pod) (rate(container_cpu_usage_seconds_total{cluster=~".+", namespace=~"agent-smoke-test", container=~".+", pod="grafana-agent-smoke-test-cluster-2"}[5m]))
        /
        (sum by (pod) (agent_wal_storage_active_series{cluster=~".+", namespace=~"agent-smoke-test", container=~".+", pod="grafana-agent-smoke-test-cluster-2"}) / 1000)
        > 0.0013441)
        and
        sum by (pod) (agent_wal_storage_active_series{cluster=~".+", namespace=~"agent-smoke-test", container=~".+", pod="grafana-agent-smoke-test-cluster-2"}) > 1000
      for: 1h
    - alert: GrafanaAgentMemHigh
      annotations:
        summary: '{{ $labels.job }} has used more than 10KB per series for more than
          5 minutes'
      expr: |
        sum without (pod, instance) (go_memstats_heap_inuse_bytes{job=~"agent-smoke-test/grafana-agent-smoke-test.*"}) /
        sum without (pod, instance, instance_group_name) (agent_wal_storage_active_series{job=~"agent-smoke-test/grafana-agent-smoke-test.*"}) / 1e3 > 10
      for: 1h
    - alert: GrafanaAgentContainerRestarts
      annotations:
        summary: '{{ $labels.pod }} has a high rate of container restarts'
      expr: |
        sum by (pod) (rate(kube_pod_container_status_restarts_total{namespace="agent-smoke-test"}[10m])) > 0
  - name: GrafanaAgentCrowChecks
    rules:
    - alert: CrowDown
      annotations:
        summary: Crow {{ $labels.job }} is down.
      expr: |
        up{job=~"agent-smoke-test/crow-.*"} == 0
      for: 5m
    - alert: CrowFlapping
      annotations:
        summary: Crow {{ $labels.job }} is flapping.
      expr: |
        avg_over_time(up{job=~"agent-smoke-test/crow-.*"}[5m]) < 1
      for: 15m
    - alert: CrowNotScraped
      annotations:
        summary: Crow {{ $labels.job }} is not being scraped.
      expr: |
        rate(crow_test_samples_total[5m]) == 0
      for: 15m
    - alert: CrowFailures
      annotations:
        summary: Crow {{ $labels.job }} has had failures for at least 5m
      expr: |
        (
            rate(crow_test_sample_results_total{result="success"}[5m])
            /
            ignoring(result) sum without (result) (rate(crow_test_sample_results_total[5m]))
        )
        < 1
      for: 15m
